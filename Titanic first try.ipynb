{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data readin as preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dat=pd.read_csv(\"train.csv\")\n",
    "\n",
    "target_attribute=[\"Survived\"]\n",
    "attributes=[\"Pclass\",\"Sex\",\"SibSp\",\"Age\",\"Parch\",\"Fare\",\"Embarked\"]\n",
    "dat=dat[target_attribute+attributes]\n",
    "\n",
    "class_attributes=[\"Sex\",\"Embarked\",\"Pclass\"]\n",
    "# filter out invalid entries\n",
    "\n",
    "\n",
    "#print dat[dat.isnull().any(axis=1)]\n",
    "dat[\"Age\"]=dat[\"Age\"].fillna(dat[\"Age\"].median())\n",
    "dat[\"Fare\"]=dat[\"Fare\"].fillna(dat[\"Fare\"].median())\n",
    "#dat[\"Fare\"]=np.log(dat[\"Fare\"])\n",
    "dat[\"SP\"]=dat[\"SibSp\"]+dat[\"Parch\"]\n",
    "#dat[\"PSA\"]=dat[\"Pclass\"]*dat[\"Sex\"]*dat[\"Age\"]\n",
    "\n",
    "dat=dat.dropna()\n",
    "\n",
    "\n",
    "#print len(dat)\n",
    "\n",
    "\n",
    "# create training and test set#\n",
    "\n",
    "y=dat[target_attribute]\n",
    "X=dat[attributes]\n",
    "\n",
    "#X[\"Persons\"]=X[\"SibSp\"]+X[\"Parch\"]\n",
    "\n",
    "# binarize class variables\n",
    "X=pd.get_dummies(X,columns=class_attributes)\n",
    "#X=X.drop(\"Sex_female\",1)\n",
    "#print X\n",
    "\n",
    "from sklearn.cross_validation import *\n",
    "X=X.values\n",
    "y=y.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import *\n",
    "\n",
    "def validate_model(model,N_folds):\n",
    "\n",
    "    #sum=0\n",
    "    #N=20\n",
    "    #vals=[]\n",
    "    #Ã¤for i in range(N_folds):\n",
    "    #    X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.1,random_state=42)\n",
    "    #    m.fit(X_train,y_train)\n",
    "    #    vals+=[m.score(X_test,y_test)]\n",
    "    vals=[];\n",
    "    for train, test in KFold(len(X),n_folds=N_folds):\n",
    "            model.fit(X[train],y[train])\n",
    "            vals+=[model.score(X[test],y[test])]\n",
    "    return [np.mean(vals),np.std(vals)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tune rft with grid search\n",
    "\"\"\"\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from time import time\n",
    "\n",
    "param_grid = {\"max_depth\": [3, None],\n",
    "              \"max_features\": [1, 3, 10],\n",
    "              \"min_samples_split\": [1, 3, 10],\n",
    "              \"min_samples_leaf\": [1, 3, 10],\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "m=RandomForestClassifier(n_estimators=20)\n",
    "# run grid search\n",
    "m = GridSearchCV(m, param_grid=param_grid)\n",
    "start = time()\n",
    "\n",
    "m.fit(X, y[\"Survived\"])\n",
    "print validate_model(m,20)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Survived\n",
      "PassengerId          \n",
      "892                 0\n",
      "893                 1\n",
      "894                 0\n",
      "895                 0\n",
      "896                 1\n",
      "897                 0\n",
      "898                 1\n",
      "899                 1\n",
      "900                 1\n",
      "901                 0\n",
      "902                 0\n",
      "903                 0\n",
      "904                 1\n",
      "905                 0\n",
      "906                 1\n",
      "907                 1\n",
      "908                 0\n",
      "909                 0\n",
      "910                 1\n",
      "911                 1\n",
      "912                 0\n",
      "913                 0\n",
      "914                 1\n",
      "915                 1\n",
      "916                 1\n",
      "917                 0\n",
      "918                 1\n",
      "919                 0\n",
      "920                 1\n",
      "921                 0\n",
      "...               ...\n",
      "1280                0\n",
      "1281                0\n",
      "1282                0\n",
      "1283                1\n",
      "1284                0\n",
      "1285                0\n",
      "1286                0\n",
      "1287                1\n",
      "1288                0\n",
      "1289                1\n",
      "1290                0\n",
      "1291                0\n",
      "1292                1\n",
      "1293                0\n",
      "1294                1\n",
      "1295                0\n",
      "1296                0\n",
      "1297                1\n",
      "1298                0\n",
      "1299                0\n",
      "1300                1\n",
      "1301                1\n",
      "1302                1\n",
      "1303                1\n",
      "1304                1\n",
      "1305                0\n",
      "1306                1\n",
      "1307                0\n",
      "1308                0\n",
      "1309                0\n",
      "\n",
      "[418 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# read in test data\n",
    "    \n",
    "dat=pd.read_csv(\"test.csv\")\n",
    "\n",
    "passenger_ids=dat[\"PassengerId\"]\n",
    "\n",
    "attributes=[\"Pclass\",\"Sex\",\"Age\",\"SibSp\",\"Parch\",\"Fare\",\"Embarked\"]\n",
    "dat=dat[attributes]\n",
    "\n",
    "class_attributes=[\"Sex\",\"Embarked\",\"Pclass\"]\n",
    "# filter out invalid entries\n",
    "\n",
    "\n",
    "dat[\"Age\"]=dat[\"Age\"].fillna(dat[\"Age\"].median())\n",
    "dat[\"Fare\"]=dat[\"Fare\"].fillna(dat[\"Fare\"].median())\n",
    "\n",
    "#print dat[dat.isnull().any(axis=1)]\n",
    "#dat=dat.dropna()\n",
    "# create training and test set#\n",
    "\n",
    "X_test=dat[attributes]\n",
    "\n",
    "# binarize class variables\n",
    "X_test=pd.get_dummies(X_test,columns=class_attributes)\n",
    "X_test=X_test.values\n",
    "\n",
    "#X_test=X_test.drop(\"Sex_female\",1)\n",
    "\n",
    "#X_test[\"Persons\"]=X_test[\"SibSp\"]+X_test[\"Parch\"]\n",
    "\n",
    "#print X_test\n",
    "\n",
    "# make predictions\n",
    "\n",
    "#print list(X_test.columns.values)\n",
    "\n",
    "m=RandomForestClassifier(n_estimators=350,n_jobs=2)\n",
    "m.fit(X,y)\n",
    "y_pred=m.predict(X_test)\n",
    "\n",
    "# save results\n",
    "\n",
    "\n",
    "#print passenger_ids\n",
    "\n",
    "preds=pd.DataFrame()\n",
    "preds[\"Survived\"]=pd.Series(y_pred,passenger_ids)\n",
    "\n",
    "print preds\n",
    "\n",
    "\n",
    "# export to csv\n",
    "#best_n=0\n",
    "#best_score=0.\n",
    "#for n in np.linspace(1,3,10):\n",
    "#    m=RandomForestClassifier(n_estimators=int(10**n),n_jobs=2)\n",
    "#    cur_score,cur_std=validate_model(m,50)\n",
    "#    print \"N: %f ==> %f +- %f\"%(int(10**n),cur_score,cur_std)\n",
    "#    \n",
    "#    if(cur_score>best_score):\n",
    "#        best_score=cur_score\n",
    "#        best_n=10**n\n",
    "    \n",
    "preds.to_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
